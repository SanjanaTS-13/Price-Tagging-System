# -*- coding: utf-8 -*-
"""Price tagging system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IKqlnipITxoOfrLTLLOe7yNdM75NnUcZ
"""

from google.colab import drive
drive.mount('/content/drive')

!cp /content/drive/MyDrive/PriceTaggingFiles/photos.zip    ./photos.zip
!unzip -q photos.zip -d ./photos

!pip install --quiet numpy pandas opencv-python matplotlib scikit-learn tensorflow ijson

import os, json
import ijson
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf

BUSINESS_JSON = "/content/drive/MyDrive/PriceTaggingFiles/business.json"
PHOTO_JSON = "/content/drive/MyDrive/PriceTaggingFiles/photos.json"
IMG_DIR = "/content/photos/photos"
IMG_SIZE = 224

with open(BUSINESS_JSON, 'r', encoding='utf8') as f:
    example = json.loads(next(f))
print(example.keys())
print(example.get('attributes'))

price_map = {'1': '$', '2': '$$', '3': '$$$', '4': '$$$$'}
biz_price = {}

with open(BUSINESS_JSON, 'r', encoding='utf8') as f:
    for line in f:
        o = json.loads(line)
        attrs = o.get('attributes') or {}
        raw = attrs.get('RestaurantsPriceRange2') or attrs.get('RestaurantsPriceRange')
        price = price_map.get(str(raw))
        if price:
            biz_price[o['business_id']] = price

print("Loaded prices for", len(biz_price), "businesses")

records = []
with open(PHOTO_JSON, 'r', encoding='utf8') as f:
    for line in f:
        o = json.loads(line)
        price = biz_price.get(o['business_id'])
        if price:
            records.append({
                'photo_id':    o['photo_id'],
                'business_id': o['business_id'],
                'price':       price
            })

df = pd.DataFrame(records)
print("Images with price:", len(df))
print(df['price'].value_counts())

df_small = (
    df
    .groupby('price', group_keys=False)
    .apply(lambda d: d.sample(min(len(d), 1000), random_state=1))
    .reset_index(drop=True)
)
print(df_small['price'].value_counts())
df = df_small

labels  = sorted(df['price'].unique())            # e.g. [1,2,3,4]
lab2idx = {lab: idx for idx, lab in enumerate(labels)}
print("Label mapping:", lab2idx)

def preprocess_image_safe(path):
    img = cv2.imread(path)
    if img is None:
        return None      # skip this one
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    return img.astype('float32') / 255.0

X, y = [], []
for _, row in df.iterrows():
    img_path = os.path.join(IMG_DIR, f"{row.photo_id}.jpg")
    processed = preprocess_image_safe(img_path)
    if processed is not None:
        X.append(processed)
        y.append(lab2idx[row.price])

X = np.stack(X)
y = np.array(y)
print("Dataset shape:", X.shape, y.shape)

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

print(f"Train set: {X_train.shape}, {y_train.shape}")
print(f" Val set: {X_val.shape}, {y_val.shape}")

from sklearn.cluster import KMeans
import pandas as pd

base_model = tf.keras.applications.MobileNetV2(
    weights='imagenet',
    include_top=False,
    pooling='avg',
    input_shape=(IMG_SIZE, IMG_SIZE, 3)
)


emb_train = base_model.predict(X_train, batch_size=64, verbose=1)

n_clusters = len(lab2idx)
km = KMeans(n_clusters=n_clusters, random_state=42)
clusters = km.fit_predict(emb_train)

print(pd.crosstab(clusters, y_train))



import numpy as np
from sklearn.utils import class_weight
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_model = tf.keras.applications.MobileNetV2(
    weights='imagenet',
    include_top=False,
    pooling='avg',
    input_shape=(IMG_SIZE, IMG_SIZE, 3)
)
base_model.trainable = False  # freeze for now

model = models.Sequential([
    base_model,
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(len(lab2idx), activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights = dict(enumerate(weights))
print("Class weights:", class_weights)

aug = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
train_gen = aug.flow(X_train, y_train, batch_size=32)

history = model.fit(
    train_gen,
    validation_data=(X_val, y_val),
    epochs=15,
    class_weight=class_weights
)

base_model.trainable = True
for layer in base_model.layers[:100]:
    layer.trainable = False

from tensorflow.keras.optimizers import Adam
model.compile(
    optimizer=Adam(1e-5),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history_ft = model.fit(
    train_gen,
    validation_data=(X_val, y_val),
    epochs=10
)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

y_prob = model.predict(X_val, batch_size=64, verbose=0)
y_pred = np.argmax(y_prob, axis=1)

idx2lab     = {idx: lab for lab, idx in lab2idx.items()}
class_names = [idx2lab[i] for i in range(len(idx2lab))]

print(classification_report(
    y_val, y_pred,
    target_names=class_names,
    digits=3
))

cm = confusion_matrix(y_val, y_pred)

escaped = [name.replace('$', r'\$') for name in class_names]

plt.figure(figsize=(6,5))
plt.imshow(cm, cmap='Blues', interpolation='nearest')
plt.title("Confusion Matrix")
plt.colorbar()

ticks = np.arange(len(escaped))
plt.xticks(ticks, escaped, rotation=45)
plt.yticks(ticks, escaped)

plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.tight_layout()
plt.show()

"""# Result
The model achieves 48.6% overall accuracy, well above a random 25% baseline.

`$` tier has the strongest recall at 70.5%, showing clear detection of budget venues.

`$$$$` tier recall is 55.0%, indicating reasonable identification of premium spots.

Mid-range tiers `$$` (40.0% recall) and `$$$` (29.0% recall) remain the hardest to classify.


"""

